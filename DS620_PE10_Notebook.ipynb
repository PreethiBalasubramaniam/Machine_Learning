{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DS620_PE10_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyvnyT6u4cdF"
      },
      "source": [
        "### Imports\n",
        "### Make sure you add to this cell as you experiement with other types of RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMI1WoJ8xYRj"
      },
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "import keras\n",
        "import keras.utils\n",
        "from keras import utils as np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from matplotlib import pyplot\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ullTjsCn2zf2"
      },
      "source": [
        "### This section deals with loading the training and testing datasets\n",
        "### it is not necessary to modify it for the PE10 assignment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ipxPCd1L9n"
      },
      "source": [
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        "\n",
        "# load a list of files and return as a 3d numpy array\n",
        "def load_group(filenames):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        "\n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset_train():\n",
        "\tfilenames = ['total_acc_x_train.txt','total_acc_y_train.txt','total_acc_z_train.txt','body_acc_x_train.txt','body_acc_y_train.txt','body_acc_z_train.txt','body_gyro_x_train.txt','body_gyro_y_train.txt','body_gyro_z_train.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames)\n",
        "\t# load class output\n",
        "\ty = load_file('y_train.txt')\n",
        "\treturn X, y\n",
        "\n",
        "def load_dataset_test():\n",
        "  filenames = ['total_acc_x_test.txt','total_acc_y_test.txt','total_acc_z_test.txt','body_acc_x_test.txt','body_acc_y_test.txt','body_acc_z_test.txt','body_gyro_x_test.txt','body_gyro_y_test.txt','body_gyro_z_test.txt']\n",
        "  # load input data\n",
        "  X = load_group(filenames)\n",
        "  # load class output\n",
        "  y = load_file('y_test.txt')\n",
        "  return X, y\n",
        "\n",
        "\n",
        "# load the dataset, returns train and test X and y elements\n",
        "def load_dataset():\n",
        "\t# load all train\n",
        "\ttrainX, trainy = load_dataset_train()\n",
        "\tprint(trainX.shape, trainy.shape)\n",
        "\t# load all test\n",
        "\ttestX, testy = load_dataset_test()\n",
        "\tprint(testX.shape, testy.shape)\n",
        "\t# zero-offset class values\n",
        "\ttrainy = trainy - 1\n",
        "\ttesty = testy - 1\n",
        "\t# one hot encode y\n",
        "\ttrainy = to_categorical(trainy)\n",
        "\ttesty = to_categorical(testy)\n",
        "\tprint(trainX.shape, trainy.shape, testX.shape, testy.shape)\n",
        "\treturn trainX, trainy, testX, testy"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4Q2f9h91o55"
      },
      "source": [
        "# Function to build, compile, and train the model\n",
        "# For PE10, copy and modify this section to try different model designs and RNNs such as simpleRNN and GRU, in addition to LSTM\n",
        "# You can try stacking the RNN layers. Refer to the Keras API on how to do this\n",
        "\n",
        "# fit and evaluate a model\n",
        "def evaluate_model(trainX, trainy, testX, testy):\n",
        "  verbose, epochs, batch_size = 0, 15, 64\n",
        "  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(100, input_shape=(n_timesteps,n_features)))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(100, activation='relu'))\n",
        "  model.add(Dense(n_outputs, activation='softmax'))\n",
        "  #model.summary()\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "  model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "  # evaluate model\n",
        "  _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "  return accuracy\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ackiwpKk4D59"
      },
      "source": [
        "### This function summarizes the results of the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z89zbCPN2Pko"
      },
      "source": [
        "# summarize scores\n",
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yTt_fVc3GoG"
      },
      "source": [
        "### This is the main code that loads the data and runs the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvbbfnMH3JT0"
      },
      "source": [
        "# run an experiment\n",
        "def run_experiment(repeats=10):\n",
        "  # load data\n",
        "  trainX, trainy, testX, testy = load_dataset()\n",
        "  # repeat experiment\n",
        "  scores = list()\n",
        "  for r in range(repeats):\n",
        "    score = evaluate_model(trainX, trainy, testX, testy)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (r+1, score))\n",
        "    scores.append(score)\n",
        "  # summarize results\n",
        "  summarize_results(scores)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgQ2I8jJ3hiX"
      },
      "source": [
        "### Running the code here:\n",
        "### Make sure you go back and modify the model design when trying out new versions for simpleRNN, LSTM and GRU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJsOqVkv3-T_",
        "outputId": "d0bd027c-12e7-451e-8f9d-832006980c23"
      },
      "source": [
        "# run the experiment\n",
        "run_experiment()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            ">#1: 90.601\n",
            ">#2: 91.686\n",
            ">#3: 89.040\n",
            ">#4: 91.042\n",
            ">#5: 89.888\n",
            ">#6: 90.499\n",
            ">#7: 89.074\n",
            ">#8: 90.261\n",
            ">#9: 90.329\n",
            ">#10: 89.175\n",
            "[90.60060977935791, 91.68646335601807, 89.03970122337341, 91.0417377948761, 89.88802433013916, 90.49881100654602, 89.07363414764404, 90.26128053665161, 90.32914638519287, 89.17543292045593]\n",
            "Accuracy: 90.159% (+/-0.833)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwdXR9jtrqhy"
      },
      "source": [
        "from keras.layers import ConvLSTM2D\n",
        "#Develop a ConvLSTM Network Model\n",
        "\n",
        "\n",
        "def evaluate_model2(trainX, trainy, testX, testy):\n",
        "\t# define model\n",
        "\tverbose, epochs, batch_size = 0, 15, 64\n",
        "\tn_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "\t# reshape into subsequences (samples, time steps, rows, cols, channels)\n",
        "\tn_steps, n_length = 4, 32\n",
        "\ttrainX = trainX.reshape((trainX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\ttestX = testX.reshape((testX.shape[0], n_steps, 1, n_length, n_features))\n",
        "\t# define model\n",
        "\tmodel2 = Sequential()\n",
        "\tmodel2.add(ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=(n_steps, 1, n_length, n_features)))\n",
        "\tmodel2.add(Dropout(0.5))\n",
        "\tmodel2.add(Flatten())\n",
        "\tmodel2.add(Dense(100, activation='relu'))\n",
        "\tmodel2.add(Dense(n_outputs, activation='softmax'))\n",
        "\tmodel2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\t# fit network\n",
        "\tmodel2.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "\t# evaluate model\n",
        "\t_, accuracy = model2.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "\treturn accuracy\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CiXEwM9tEK0"
      },
      "source": [
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMKwhyfmtM60"
      },
      "source": [
        "# run an experiment\n",
        "def run_experiment(repeats=5):\n",
        "  # load data\n",
        "  trainX, trainy, testX, testy = load_dataset()\n",
        "  # repeat experiment\n",
        "  scores = list()\n",
        "  for r in range(repeats):\n",
        "    score = evaluate_model2(trainX, trainy, testX, testy)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (r+1, score))\n",
        "    scores.append(score)\n",
        "  # summarize results\n",
        "  summarize_results(scores)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0lBmeqttTZ0",
        "outputId": "04e86bb0-1ea9-4cca-b934-ef8524e8997d"
      },
      "source": [
        "# run the experiment\n",
        "run_experiment()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            ">#1: 90.329\n",
            ">#2: 92.162\n",
            ">#3: 91.177\n",
            ">#4: 91.245\n",
            ">#5: 89.243\n",
            "[90.32914638519287, 92.16151833534241, 91.17746949195862, 91.24533534049988, 89.24329876899719]\n",
            "Accuracy: 90.831% (+/-0.983)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD374lIdh6Fx"
      },
      "source": [
        "\n",
        "\n",
        "from keras.layers import SimpleRNN\n",
        "#Develop a SimpleRNN\n",
        "\n",
        "\n",
        "def evaluate_model3(trainX, trainy, testX, testy):\n",
        "  verbose, epochs, batch_size = 0, 15, 64\n",
        "  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "  model3 = Sequential()\n",
        "  model3.add(SimpleRNN(100, input_shape=(n_timesteps,n_features)))\n",
        "  model3.add(Dropout(0.5))\n",
        "  model3.add(Dense(100, activation='relu'))\n",
        "  model3.add(Dense(n_outputs, activation='softmax'))\n",
        "  #model.summary()\n",
        "  model3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "  model3.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "  # evaluate model\n",
        "  _, accuracy = model3.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "  return accuracy\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD6TWqzoitQ2"
      },
      "source": [
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL_YPzh-i1tA"
      },
      "source": [
        "# run an experiment\n",
        "def run_experiment(repeats=5):\n",
        "  # load data\n",
        "  trainX, trainy, testX, testy = load_dataset()\n",
        "  # repeat experiment\n",
        "  scores = list()\n",
        "  for r in range(repeats):\n",
        "    score = evaluate_model3(trainX, trainy, testX, testy)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (r+1, score))\n",
        "    scores.append(score)\n",
        "  # summarize results\n",
        "  summarize_results(scores)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIF_-h-rjBjz",
        "outputId": "b2506c5a-4191-4be0-d1c2-4e061fc87098"
      },
      "source": [
        "run_experiment()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            ">#1: 71.021\n",
            ">#2: 70.750\n",
            ">#3: 57.279\n",
            ">#4: 85.918\n",
            ">#5: 64.201\n",
            "[71.02137804031372, 70.74991464614868, 57.27858543395996, 85.91788411140442, 64.20088410377502]\n",
            "Accuracy: 69.834% (+/-9.490)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD7IAb6_jS9Z"
      },
      "source": [
        "# Develop a GRU model\n",
        "from keras.layers import GRU\n",
        "\n",
        "def evaluate_model3(trainX, trainy, testX, testy):\n",
        "  verbose, epochs, batch_size = 0, 15, 64\n",
        "  n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
        "  model4 = Sequential()\n",
        "  model4.add(GRU(100, input_shape=(n_timesteps,n_features)))\n",
        "  model4.add(Dropout(0.5))\n",
        "  model4.add(Dense(100, activation='relu'))\n",
        "  model4.add(Dense(n_outputs, activation='softmax'))\n",
        "  #model.summary()\n",
        "  model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  # fit network\n",
        "  model4.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
        "  # evaluate model\n",
        "  _, accuracy = model4.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
        "  return accuracy\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZogcf4Djh5S"
      },
      "source": [
        "def summarize_results(scores):\n",
        "\tprint(scores)\n",
        "\tm, s = mean(scores), std(scores)\n",
        "\tprint('Accuracy: %.3f%% (+/-%.3f)' % (m, s))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zic8d0UAjo41"
      },
      "source": [
        "# run an experiment\n",
        "def run_experiment(repeats=5):\n",
        "  # load data\n",
        "  trainX, trainy, testX, testy = load_dataset()\n",
        "  # repeat experiment\n",
        "  scores = list()\n",
        "  for r in range(repeats):\n",
        "    score = evaluate_model4(trainX, trainy, testX, testy)\n",
        "    score = score * 100.0\n",
        "    print('>#%d: %.3f' % (r+1, score))\n",
        "    scores.append(score)\n",
        "  # summarize results\n",
        "  summarize_results(scores)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjswPvwfjyPR",
        "outputId": "6152ae66-4584-4262-c94a-75d6e04c5a89"
      },
      "source": [
        "run_experiment()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9) (7352, 1)\n",
            "(2947, 128, 9) (2947, 1)\n",
            "(7352, 128, 9) (7352, 6) (2947, 128, 9) (2947, 6)\n",
            ">#1: 73.057\n",
            ">#2: 80.014\n",
            ">#3: 82.321\n",
            ">#4: 70.445\n",
            ">#5: 53.885\n",
            "[73.05734753608704, 80.01357316970825, 82.3210060596466, 70.44451832771301, 53.88530492782593]\n",
            "Accuracy: 71.944% (+/-10.024)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}